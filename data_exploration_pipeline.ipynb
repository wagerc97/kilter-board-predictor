{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kilter Board Data Exploration Pipeline\n",
    "\n",
    "This notebook provides a comprehensive data exploration pipeline for analyzing SQLite database containing climbing route data.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Database Connection](#setup)\n",
    "2. [Database Schema Exploration](#schema)\n",
    "3. [Data Quality Assessment](#quality)\n",
    "4. [Exploratory Data Analysis](#eda)\n",
    "5. [Statistical Analysis](#stats)\n",
    "6. [Visualization Pipeline](#viz)\n",
    "7. [Export and Reporting](#export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Database Connection {#setup}\n",
    "\n",
    "First, let's import all necessary libraries and establish connection to our SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Database handling\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Jupyter widgets for interactivity\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection setup\n",
    "DATABASE_PATH = 'kilter_board_data.db'\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"Create and return a database connection.\"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(DATABASE_PATH)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to database: {e}\")\n",
    "        return None\n",
    "\n",
    "def execute_query(query, params=None):\n",
    "    \"\"\"Execute a query and return results as a pandas DataFrame.\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    if conn:\n",
    "        try:\n",
    "            df = pd.read_sql_query(query, conn, params=params)\n",
    "            conn.close()\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing query: {e}\")\n",
    "            conn.close()\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Test connection\n",
    "test_conn = get_db_connection()\n",
    "if test_conn:\n",
    "    print(\"✅ Database connection successful!\")\n",
    "    test_conn.close()\n",
    "else:\n",
    "    print(\"❌ Database connection failed. Make sure to run 'python create_sample_db.py' first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Schema Exploration {#schema}\n",
    "\n",
    "Let's explore the database structure and understand our data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all tables\n",
    "tables_query = \"\"\"\n",
    "SELECT name FROM sqlite_master \n",
    "WHERE type='table' AND name NOT LIKE 'sqlite_%'\n",
    "ORDER BY name;\n",
    "\"\"\"\n",
    "\n",
    "tables_df = execute_query(tables_query)\n",
    "print(\"Database Tables:\")\n",
    "print(\"=\" * 20)\n",
    "for table in tables_df['name']:\n",
    "    print(f\"📋 {table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get schema information for each table\n",
    "def get_table_schema(table_name):\n",
    "    \"\"\"Get schema information for a specific table.\"\"\"\n",
    "    schema_query = f\"PRAGMA table_info({table_name})\"\n",
    "    return execute_query(schema_query)\n",
    "\n",
    "# Display schema for all tables\n",
    "for table in tables_df['name']:\n",
    "    print(f\"\\n🔍 Schema for '{table}' table:\")\n",
    "    schema = get_table_schema(table)\n",
    "    print(schema.to_string(index=False))\n",
    "    \n",
    "    # Get row count\n",
    "    count_query = f\"SELECT COUNT(*) as row_count FROM {table}\"\n",
    "    count_result = execute_query(count_query)\n",
    "    print(f\"📊 Total rows: {count_result['row_count'].iloc[0]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment {#quality}\n",
    "\n",
    "Let's assess the quality of our data by checking for missing values, duplicates, and data consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all tables into DataFrames for analysis\n",
    "holds_df = execute_query(\"SELECT * FROM holds\")\n",
    "routes_df = execute_query(\"SELECT * FROM routes\")\n",
    "route_holds_df = execute_query(\"SELECT * FROM route_holds\")\n",
    "attempts_df = execute_query(\"SELECT * FROM user_attempts\")\n",
    "\n",
    "# Create a dictionary for easy access\n",
    "dataframes = {\n",
    "    'holds': holds_df,\n",
    "    'routes': routes_df,\n",
    "    'route_holds': route_holds_df,\n",
    "    'user_attempts': attempts_df\n",
    "}\n",
    "\n",
    "print(\"✅ All tables loaded into DataFrames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality assessment function\n",
    "def assess_data_quality(df, table_name):\n",
    "    \"\"\"Assess data quality for a given DataFrame.\"\"\"\n",
    "    print(f\"\\n📊 Data Quality Report for '{table_name}' table:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "    \n",
    "    # Missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum() > 0:\n",
    "        print(\"\\n❌ Missing Values:\")\n",
    "        for col, count in missing_values[missing_values > 0].items():\n",
    "            percentage = (count / len(df)) * 100\n",
    "            print(f\"  {col}: {count} ({percentage:.2f}%)\")\n",
    "    else:\n",
    "        print(\"\\n✅ No missing values found\")\n",
    "    \n",
    "    # Duplicate rows\n",
    "    duplicates = df.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print(f\"\\n❌ Duplicate rows: {duplicates}\")\n",
    "    else:\n",
    "        print(\"\\n✅ No duplicate rows found\")\n",
    "    \n",
    "    # Data types\n",
    "    print(\"\\n📋 Data Types:\")\n",
    "    for col, dtype in df.dtypes.items():\n",
    "        print(f\"  {col}: {dtype}\")\n",
    "    \n",
    "    return {\n",
    "        'shape': df.shape,\n",
    "        'missing_values': missing_values.sum(),\n",
    "        'duplicates': duplicates,\n",
    "        'memory_usage_kb': df.memory_usage(deep=True).sum() / 1024\n",
    "    }\n",
    "\n",
    "# Assess quality for all tables\n",
    "quality_reports = {}\n",
    "for table_name, df in dataframes.items():\n",
    "    quality_reports[table_name] = assess_data_quality(df, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary quality dashboard\n",
    "quality_summary = pd.DataFrame(quality_reports).T\n",
    "quality_summary.columns = ['Shape', 'Missing Values', 'Duplicates', 'Memory (KB)']\n",
    "quality_summary['Rows'] = quality_summary['Shape'].apply(lambda x: x[0])\n",
    "quality_summary['Columns'] = quality_summary['Shape'].apply(lambda x: x[1])\n",
    "quality_summary = quality_summary[['Rows', 'Columns', 'Missing Values', 'Duplicates', 'Memory (KB)']]\n",
    "\n",
    "print(\"\\n📋 Data Quality Summary:\")\n",
    "print(\"=\" * 30)\n",
    "print(quality_summary.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis {#eda}\n",
    "\n",
    "Now let's dive into exploring our data with descriptive statistics and initial insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for numerical columns\n",
    "print(\"📊 Descriptive Statistics for Holds:\")\n",
    "print(\"=\" * 40)\n",
    "print(holds_df.describe())\n",
    "\n",
    "print(\"\\n📊 Descriptive Statistics for Routes:\")\n",
    "print(\"=\" * 40)\n",
    "print(routes_df.describe())\n",
    "\n",
    "print(\"\\n📊 Descriptive Statistics for User Attempts:\")\n",
    "print(\"=\" * 40)\n",
    "print(attempts_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical analysis\n",
    "print(\"🏷️ Hold Types Distribution:\")\n",
    "hold_types = holds_df['hold_type'].value_counts()\n",
    "print(hold_types)\n",
    "\n",
    "print(\"\\n🎯 Grade Distribution:\")\n",
    "grade_dist = routes_df['grade'].value_counts().sort_index()\n",
    "print(grade_dist)\n",
    "\n",
    "print(\"\\n👤 Setter Distribution:\")\n",
    "setter_dist = routes_df['setter_name'].value_counts()\n",
    "print(setter_dist)\n",
    "\n",
    "print(\"\\n🎪 Attempt Results Distribution:\")\n",
    "attempt_results = attempts_df['attempt_result'].value_counts()\n",
    "print(attempt_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced queries for insights\n",
    "insights_queries = {\n",
    "    'route_difficulty_by_setter': \"\"\"\n",
    "        SELECT setter_name, AVG(grade_numeric) as avg_difficulty, COUNT(*) as routes_set\n",
    "        FROM routes \n",
    "        GROUP BY setter_name \n",
    "        ORDER BY avg_difficulty DESC\n",
    "    \"\"\",\n",
    "    \n",
    "    'success_rate_by_grade': \"\"\"\n",
    "        SELECT r.grade, \n",
    "               COUNT(CASE WHEN ua.attempt_result IN ('flash', 'send') THEN 1 END) as successful_attempts,\n",
    "               COUNT(*) as total_attempts,\n",
    "               ROUND(COUNT(CASE WHEN ua.attempt_result IN ('flash', 'send') THEN 1 END) * 100.0 / COUNT(*), 2) as success_rate\n",
    "        FROM user_attempts ua\n",
    "        JOIN routes r ON ua.route_id = r.id\n",
    "        GROUP BY r.grade\n",
    "        ORDER BY r.grade_numeric\n",
    "    \"\"\",\n",
    "    \n",
    "    'most_popular_routes': \"\"\"\n",
    "        SELECT r.name, r.grade, COUNT(*) as attempt_count,\n",
    "               ROUND(AVG(ua.difficulty_rating), 2) as avg_user_rating\n",
    "        FROM user_attempts ua\n",
    "        JOIN routes r ON ua.route_id = r.id\n",
    "        GROUP BY r.id, r.name, r.grade\n",
    "        ORDER BY attempt_count DESC\n",
    "        LIMIT 10\n",
    "    \"\"\",\n",
    "    \n",
    "    'hold_usage_stats': \"\"\"\n",
    "        SELECT h.hold_type, COUNT(*) as usage_count, AVG(h.difficulty_contribution) as avg_difficulty\n",
    "        FROM holds h\n",
    "        JOIN route_holds rh ON h.id = rh.hold_id\n",
    "        GROUP BY h.hold_type\n",
    "        ORDER BY usage_count DESC\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Execute insight queries\n",
    "insights = {}\n",
    "for query_name, query in insights_queries.items():\n",
    "    result = execute_query(query)\n",
    "    insights[query_name] = result\n",
    "    print(f\"\\n🔍 {query_name.replace('_', ' ').title()}:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(result.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Analysis {#stats}\n",
    "\n",
    "Let's perform some statistical analysis to understand relationships and correlations in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "numerical_cols = ['grade_numeric', 'difficulty_rating', 'attempts_count']\n",
    "\n",
    "# Create a comprehensive dataset for correlation analysis\n",
    "analysis_df = execute_query(\"\"\"\n",
    "    SELECT \n",
    "        r.grade_numeric,\n",
    "        ua.difficulty_rating,\n",
    "        ua.attempts_count,\n",
    "        CASE WHEN ua.attempt_result IN ('flash', 'send') THEN 1 ELSE 0 END as success,\n",
    "        ua.user_id,\n",
    "        r.id as route_id\n",
    "    FROM user_attempts ua\n",
    "    JOIN routes r ON ua.route_id = r.id\n",
    "\"\"\")\n",
    "\n",
    "print(\"📊 Correlation Matrix:\")\n",
    "correlation_matrix = analysis_df[numerical_cols].corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Statistical tests\n",
    "from scipy import stats\n",
    "\n",
    "print(\"\\n🧮 Statistical Tests:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Test correlation between grade and user difficulty rating\n",
    "correlation, p_value = stats.pearsonr(analysis_df['grade_numeric'], analysis_df['difficulty_rating'])\n",
    "print(f\"Grade vs User Rating Correlation: {correlation:.3f} (p-value: {p_value:.3f})\")\n",
    "\n",
    "# Test correlation between grade and attempts needed\n",
    "correlation, p_value = stats.pearsonr(analysis_df['grade_numeric'], analysis_df['attempts_count'])\n",
    "print(f\"Grade vs Attempts Correlation: {correlation:.3f} (p-value: {p_value:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User performance analysis\n",
    "user_stats = execute_query(\"\"\"\n",
    "    SELECT \n",
    "        user_id,\n",
    "        COUNT(*) as total_attempts,\n",
    "        COUNT(CASE WHEN attempt_result IN ('flash', 'send') THEN 1 END) as successful_attempts,\n",
    "        ROUND(COUNT(CASE WHEN attempt_result IN ('flash', 'send') THEN 1 END) * 100.0 / COUNT(*), 2) as success_rate,\n",
    "        AVG(difficulty_rating) as avg_perceived_difficulty,\n",
    "        MAX(r.grade_numeric) as hardest_grade_attempted,\n",
    "        AVG(attempts_count) as avg_attempts_per_route\n",
    "    FROM user_attempts ua\n",
    "    JOIN routes r ON ua.route_id = r.id\n",
    "    GROUP BY user_id\n",
    "    HAVING total_attempts >= 10\n",
    "    ORDER BY success_rate DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"👥 User Performance Statistics:\")\n",
    "print(\"=\" * 40)\n",
    "print(user_stats.head(10).to_string(index=False))\n",
    "\n",
    "print(f\"\\n📈 Performance Summary:\")\n",
    "print(f\"Average Success Rate: {user_stats['success_rate'].mean():.2f}%\")\n",
    "print(f\"Median Success Rate: {user_stats['success_rate'].median():.2f}%\")\n",
    "print(f\"Best Performer: User {user_stats.iloc[0]['user_id']} ({user_stats.iloc[0]['success_rate']:.2f}% success rate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization Pipeline {#viz}\n",
    "\n",
    "Now let's create comprehensive visualizations to better understand our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plotting environment\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Kilter Board Data Overview', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Hold types distribution\n",
    "hold_types.plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('Distribution of Hold Types')\n",
    "axes[0,0].set_xlabel('Hold Type')\n",
    "axes[0,0].set_ylabel('Count')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 2: Grade distribution\n",
    "grade_dist.plot(kind='bar', ax=axes[0,1], color='lightcoral')\n",
    "axes[0,1].set_title('Distribution of Route Grades')\n",
    "axes[0,1].set_xlabel('Grade')\n",
    "axes[0,1].set_ylabel('Count')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 3: Attempt results\n",
    "attempt_results.plot(kind='pie', ax=axes[1,0], autopct='%1.1f%%')\n",
    "axes[1,0].set_title('Attempt Results Distribution')\n",
    "axes[1,0].set_ylabel('')\n",
    "\n",
    "# Plot 4: Success rate by grade\n",
    "success_by_grade = insights['success_rate_by_grade']\n",
    "axes[1,1].bar(success_by_grade['grade'], success_by_grade['success_rate'], color='lightgreen')\n",
    "axes[1,1].set_title('Success Rate by Grade')\n",
    "axes[1,1].set_xlabel('Grade')\n",
    "axes[1,1].set_ylabel('Success Rate (%)')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Plotly visualizations\n",
    "# 1. Hold positions on the board\n",
    "fig_holds = px.scatter(holds_df, x='position_x', y='position_y', \n",
    "                      color='hold_type', size='difficulty_contribution',\n",
    "                      title='Hold Positions on Kilter Board',\n",
    "                      labels={'position_x': 'X Position (%)', 'position_y': 'Y Position (%)'},\n",
    "                      width=800, height=600)\n",
    "fig_holds.update_layout(showlegend=True)\n",
    "fig_holds.show()\n",
    "\n",
    "# 2. User performance heatmap\n",
    "user_grade_performance = execute_query(\"\"\"\n",
    "    SELECT \n",
    "        ua.user_id,\n",
    "        r.grade,\n",
    "        COUNT(CASE WHEN ua.attempt_result IN ('flash', 'send') THEN 1 END) as successes,\n",
    "        COUNT(*) as attempts\n",
    "    FROM user_attempts ua\n",
    "    JOIN routes r ON ua.route_id = r.id\n",
    "    GROUP BY ua.user_id, r.grade\n",
    "    HAVING attempts >= 3\n",
    "\"\"\")\n",
    "user_grade_performance['success_rate'] = user_grade_performance['successes'] / user_grade_performance['attempts']\n",
    "\n",
    "# Create pivot table for heatmap\n",
    "heatmap_data = user_grade_performance.pivot(index='user_id', columns='grade', values='success_rate')\n",
    "heatmap_data = heatmap_data.fillna(0)\n",
    "\n",
    "fig_heatmap = px.imshow(heatmap_data, \n",
    "                       title='User Success Rate by Grade',\n",
    "                       labels={'x': 'Grade', 'y': 'User ID', 'color': 'Success Rate'},\n",
    "                       aspect='auto',\n",
    "                       color_continuous_scale='RdYlGn')\n",
    "fig_heatmap.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced time series analysis\n",
    "# Convert timestamp to datetime\n",
    "attempts_df['attempted_at'] = pd.to_datetime(attempts_df['attempted_at'])\n",
    "attempts_df['date'] = attempts_df['attempted_at'].dt.date\n",
    "attempts_df['month'] = attempts_df['attempted_at'].dt.to_period('M')\n",
    "\n",
    "# Daily activity\n",
    "daily_activity = attempts_df.groupby('date').size().reset_index(name='attempts')\n",
    "daily_activity['date'] = pd.to_datetime(daily_activity['date'])\n",
    "\n",
    "fig_time = px.line(daily_activity, x='date', y='attempts',\n",
    "                  title='Daily Climbing Activity Over Time',\n",
    "                  labels={'date': 'Date', 'attempts': 'Number of Attempts'})\n",
    "fig_time.show()\n",
    "\n",
    "# Monthly success rate trends\n",
    "monthly_stats = attempts_df.groupby('month').agg({\n",
    "    'attempt_result': lambda x: (x.isin(['flash', 'send'])).sum(),\n",
    "    'id': 'count'\n",
    "}).reset_index()\n",
    "monthly_stats.columns = ['month', 'successes', 'total_attempts']\n",
    "monthly_stats['success_rate'] = monthly_stats['successes'] / monthly_stats['total_attempts']\n",
    "monthly_stats['month_str'] = monthly_stats['month'].astype(str)\n",
    "\n",
    "fig_monthly = px.bar(monthly_stats, x='month_str', y='success_rate',\n",
    "                    title='Monthly Success Rate Trends',\n",
    "                    labels={'month_str': 'Month', 'success_rate': 'Success Rate'})\n",
    "fig_monthly.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive dashboard with widgets\n",
    "def create_interactive_analysis():\n",
    "    \"\"\"Create interactive widgets for data exploration.\"\"\"\n",
    "    \n",
    "    # Widget for grade selection\n",
    "    grade_widget = widgets.SelectMultiple(\n",
    "        options=list(routes_df['grade'].unique()),\n",
    "        value=list(routes_df['grade'].unique())[:3],\n",
    "        description='Grades:',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    # Widget for hold type selection\n",
    "    hold_widget = widgets.SelectMultiple(\n",
    "        options=list(holds_df['hold_type'].unique()),\n",
    "        value=list(holds_df['hold_type'].unique()),\n",
    "        description='Hold Types:',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    def update_analysis(selected_grades, selected_holds):\n",
    "        \"\"\"Update analysis based on widget selections.\"\"\"\n",
    "        filtered_query = f\"\"\"\n",
    "            SELECT r.grade, COUNT(*) as route_count, AVG(ua.difficulty_rating) as avg_rating\n",
    "            FROM routes r\n",
    "            LEFT JOIN user_attempts ua ON r.id = ua.route_id\n",
    "            WHERE r.grade IN ({','.join([f\"'{g}'\" for g in selected_grades])})\n",
    "            GROUP BY r.grade\n",
    "            ORDER BY r.grade_numeric\n",
    "        \"\"\"\n",
    "        \n",
    "        result = execute_query(filtered_query)\n",
    "        \n",
    "        if result is not None and not result.empty:\n",
    "            fig = px.bar(result, x='grade', y='route_count',\n",
    "                        title=f'Route Count for Selected Grades',\n",
    "                        color='avg_rating')\n",
    "            fig.show()\n",
    "    \n",
    "    # Create interactive widget\n",
    "    interactive_plot = widgets.interactive(update_analysis, \n",
    "                                         selected_grades=grade_widget,\n",
    "                                         selected_holds=hold_widget)\n",
    "    \n",
    "    display(interactive_plot)\n",
    "\n",
    "# Create the interactive dashboard\n",
    "create_interactive_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export and Reporting {#export}\n",
    "\n",
    "Finally, let's create export capabilities and generate summary reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export functions\n",
    "def export_summary_report():\n",
    "    \"\"\"Generate and export a comprehensive summary report.\"\"\"\n",
    "    \n",
    "    report = {\n",
    "        'database_overview': {\n",
    "            'total_holds': len(holds_df),\n",
    "            'total_routes': len(routes_df),\n",
    "            'total_attempts': len(attempts_df),\n",
    "            'unique_users': attempts_df['user_id'].nunique(),\n",
    "            'date_range': f\"{attempts_df['attempted_at'].min()} to {attempts_df['attempted_at'].max()}\"\n",
    "        },\n",
    "        'route_statistics': {\n",
    "            'grade_distribution': routes_df['grade'].value_counts().to_dict(),\n",
    "            'setter_distribution': routes_df['setter_name'].value_counts().to_dict(),\n",
    "            'average_difficulty': routes_df['grade_numeric'].mean()\n",
    "        },\n",
    "        'performance_metrics': {\n",
    "            'overall_success_rate': len(attempts_df[attempts_df['attempt_result'].isin(['flash', 'send'])]) / len(attempts_df) * 100,\n",
    "            'average_attempts_per_route': attempts_df['attempts_count'].mean(),\n",
    "            'most_difficult_grade': routes_df.loc[routes_df['grade_numeric'].idxmax(), 'grade'],\n",
    "            'most_popular_route': insights['most_popular_routes'].iloc[0]['name']\n",
    "        },\n",
    "        'data_quality': quality_reports\n",
    "    }\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate the report\n",
    "summary_report = export_summary_report()\n",
    "\n",
    "print(\"📋 KILTER BOARD DATA ANALYSIS SUMMARY REPORT\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "print(\"\\n🗄️ Database Overview:\")\n",
    "for key, value in summary_report['database_overview'].items():\n",
    "    print(f\"  {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "print(\"\\n📊 Route Statistics:\")\n",
    "print(f\"  Average Difficulty: {summary_report['route_statistics']['average_difficulty']:.2f}\")\n",
    "print(f\"  Most Common Grade: {max(summary_report['route_statistics']['grade_distribution'], key=summary_report['route_statistics']['grade_distribution'].get)}\")\n",
    "print(f\"  Most Active Setter: {max(summary_report['route_statistics']['setter_distribution'], key=summary_report['route_statistics']['setter_distribution'].get)}\")\n",
    "\n",
    "print(\"\\n🎯 Performance Metrics:\")\n",
    "for key, value in summary_report['performance_metrics'].items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key.replace('_', ' ').title()}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {key.replace('_', ' ').title()}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to CSV files\n",
    "def export_to_csv():\n",
    "    \"\"\"Export processed data to CSV files for further analysis.\"\"\"\n",
    "    \n",
    "    # Create exports directory\n",
    "    import os\n",
    "    os.makedirs('exports', exist_ok=True)\n",
    "    \n",
    "    # Export main datasets\n",
    "    holds_df.to_csv('exports/holds_data.csv', index=False)\n",
    "    routes_df.to_csv('exports/routes_data.csv', index=False)\n",
    "    attempts_df.to_csv('exports/attempts_data.csv', index=False)\n",
    "    \n",
    "    # Export analysis results\n",
    "    user_stats.to_csv('exports/user_performance_stats.csv', index=False)\n",
    "    \n",
    "    for name, df in insights.items():\n",
    "        df.to_csv(f'exports/{name}.csv', index=False)\n",
    "    \n",
    "    print(\"✅ Data exported to CSV files in 'exports/' directory\")\n",
    "    print(\"Files created:\")\n",
    "    for file in os.listdir('exports'):\n",
    "        print(f\"  📄 {file}\")\n",
    "\n",
    "# Export the data\n",
    "export_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save report as JSON for programmatic access\n",
    "import json\n",
    "\n",
    "with open('exports/analysis_report.json', 'w') as f:\n",
    "    json.dump(summary_report, f, indent=2, default=str)\n",
    "\n",
    "print(\"✅ Complete analysis report saved as 'exports/analysis_report.json'\")\n",
    "\n",
    "# Display final summary\n",
    "print(\"\\n🎉 DATA EXPLORATION PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 55)\n",
    "print(\"✅ Database connection established and tested\")\n",
    "print(\"✅ Schema exploration completed\")\n",
    "print(\"✅ Data quality assessment performed\")\n",
    "print(\"✅ Exploratory data analysis conducted\")\n",
    "print(\"✅ Statistical analysis completed\")\n",
    "print(\"✅ Comprehensive visualizations created\")\n",
    "print(\"✅ Data exported for further analysis\")\n",
    "print(\"✅ Summary report generated\")\n",
    "print(\"\\n📁 All results saved in 'exports/' directory\")\n",
    "print(\"\\n🔬 Ready for advanced analysis and modeling!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}